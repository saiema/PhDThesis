\chapter[Testing]{Testing}
\label{cap:preliminares.testing}

Garantizar que un programa realiza de manera correcta las tareas para las cuales fue desarrollado se encuentra dentro de los problemas m\'as desafiantes y uno de los m\'as importantes temas de investigaci\'on en el contexto de la Ingenier\'ia de Software \cite{bibliography.books.GhezziBook,bibliography.books.PressmanBook,DBLP:series/txcs/Jalote05}. Es un tema central en la calidad de software, que demanda una cantidad significativa de recursos \cite{bibliography.books.JaloteBook}, y por lo tanto tiene impacto sustancial en el costo de producci\'on de software. 

La introducci\'on de defectos puede ocurrir en cualquier etapa del desarrollo del software. El costo de resolver los problemas asociados a corregir estas deficiencias, sin embargo, cambia sutancialmente de acuerdo a la etapa en la cual fue introducido y cu\'ando fue detectado: detectar un error introducido en la etapa de requisitos (por ejemplo, comprensi\'on err\'onea de alg\'un aspecto del problema a resolver) en la etapa de testing puede costar hasta 100 veces m\'as que hacerlo durante la etapa de requisitos, donde fue introducido \cite{bibliography.books.JaloteBook}. De la misma manera, las t\'ecnicas para la detecci\'on de defectos de software cambian, de acuerdo al tipo de defecto, y a la etapa del proceso de desarrollo en la que se aplican. El \emph{testing}, que en esencia consiste en ejecutar un programa bajo un conjunto espec\'ifico de escenarios, contrastando el comportamiento actual con el esperado \cite{bibliography.books.AmmannOffutt}, es el enfoque m\'as com\'unmente usado para la detecci\'on de defectos de software, que dada su naturaleza, se aplica luego de la implementaci\'on de funcionalidad a evaluar. A pesar de sus conocidas limitaciones, que E.~W.~Dijkstra resumi\'o notablemente en su conocida frase \emph{``Program testing can be used to show the presence of bugs, but never to show their absence!''} \cite{Dijkstra:1972:CIN:1243380.1243381}, testing es la t\'ecnica de mayor aplicaci\'on, en la pr\'actica, para brindar garant\'ias (parciales) de calidad de software. La limitaci\'on central del testing est\'a asociada al hecho de que en general es inviable, o imposible, ejecutar de manera exhaustiva un programa bajo todos sus posibles escenarios de ejecuci\'on (es decir, considerando todas sus las entradas, directas e indirectas). Por esta raz\'on, es necesario seleccionar una muestra, un subconjunto de todos los escenarios posibles, sobre los cuales se realizar\'a la evaluaci\'on del comportamiento del software. Claramente, el testing, como t\'ecnica de verificaci\'on, es una t\'ecnica necesariamente incompleta, aunque goza de una simplicidad y escalabilidad que otros enfoques de verificaci\'on, especialmente aquellos basados en an\'alisis est\'atico, tienen dificultades de alcanzar.

Un \emph{test} consta b\'asicamente de los siguientes pasos: 
\begin{enumerate}
	\item Preparaci\'on (\emph{Arrange}), define los datos necesarios para el escenario bajo el cual se va a ejecutar el test. A modo de ejemplo, consideremos el test de la Figura~\ref{figures.examples.test.manual}. La primera l\'inea de este test, en la cual se define el escenario sobre el cual se va a evaluar la implementaci\'on de una calculadora, corresponde al \emph{arrange}.
	
	\item Ejecuci\'on (\emph{Act}), es la ejecuci\'on del programa a evaluar. Generalmente incluye la obtenci\'on del resultado de dicha ejecuci\'on, para su posterior contrastaci\'on con el resultado esperado. La l\'inea 2 de la Figura-\ref{figures.examples.test.manual} ejecuta una funcionalidad de la calculadora, a trav\'es del el m\'etodo \texttt{Calculator\#evaluate(String)}, para la expresi\'on definida en el arrange; esta l\'inea corresponde al \emph{act} del test. 
	
	\item Evaluaci\'on (\emph{Assert}), consiste en la verificaci\'on de que el resultado obtenido, ya sea un valor de salida o un estado del programa, se corresponde con el esperado. La \'ultima l\'inea de la Figura-\ref{figures.examples.test.manual} eval\'ua que la ejecuci\'on del m\'etodo \texttt{Calculator\#evaluate(String)}, para la expresi\'on definida en el arrange, da como resultado \texttt{16}; esta l\'inea corresponde al \emph{assert} del test.
\end{enumerate}

\begin{figure}
	\begin{lstlisting}[frame=single, mathescape=true,numbers=left,framexleftmargin=1.5em]
 la entrada a evaluar es "(1 + 3)^2"
 evaluar Calculator#evaluate con la entrada anterior
 el resultado obtenido debe ser 16
	\end{lstlisting}
	\caption{Ejemplo de un test}
	\label{figures.examples.test.manual}
\end{figure}

Evidentemente, c\'omo se elige la muestra de entradas que ser\'a utilizada para testing afecta significativamente la habilidad del proceso de testing en la detecci\'on de fallas en el software. Recordemos que el programa bajo an\'alisis se evaluar\'a sobre un conjunto de entradas, con la intenci\'on de verificar que el comportamiento real del software coincide con el esperado en estos casos, y a partir de este resultado ``generalizar'' el restulado a todos los posibles escenarios de ejecuci\'on. Dado que la selecci\'on de los escenarios para testing es crucial para este proceso, se necesita alg\'un tipo de criterio, denominado criterio de testing, que asista en la selecci\'on de los escenarios. Los criterios de testing ayudar a seleccionar escenarios, y al mismo tiempo sirven como \emph{m\'etricas} de la calidad de conjuntos de tests. 

Los criterios de testing t\'ipicamente se clasifican en \emph{caja blanca} (white box), si tienen en cuenta la estructura del c\'odigo bajo an\'alisis, o \emph{caja negra} (black box), si en cambio se concentran en la especificaci\'on del programa bajo prueba. Los criterios de testing, independientemente de la clase a la que pertenezcan, definen, directa o indirectamente, una m\'etrica, que permite evaluar la calidad de una test suite. Esta medida se puede entender como una m\'etrica de cu\'an exhaustivamente eval\'ua una test suite el comportamiento del software, o equivalentemente, cu\'an probable es que existan defectos en el software, que pasen desapercibidos a la suite. Las medidas son, por supuesto, indirectas. 

\section{Automatizaci\'on}
\label{sec:preliminares.testing.automation}

La definici\'on de que es un test, dada anteriormente, no es ejecutable, sin\'o que define una serie de pasos que deber\'ia seguir un individuo para evaluar un programa bajo un escenario particular y analizar si el resultado obtenido corresponde con el esperado. \'Esto, si bien permite evaluar un programa, es evidentemente una metodolog\'ia tediosa y por su naturaleza manual, altamente susceptible a errores humanos, adem\'as de consumir mucho tiempo. Sin embargo es evidente que se trata de un proceso altamente automatizable.

Existen numerosas librer\'ias disponibles para automatizar el proceso de testing, en la Figura-\ref{figures.examples.test.junit} se muestra el ejemplo anterior implementado en \emph{Java} utilizando la librer\'ia \emph{JUnit}.

\begin{figure}
	\begin{lstlisting}[frame=single, mathescape=true,numbers=left,framexleftmargin=1.5em]
  String expression = "(1 + 3)^2";
  Integer result = calculator.evaluate(expression);
  assertEquals(new Integer(16),result);
	\end{lstlisting}
	\caption{Ejemplo de un test JUnit}
	\label{figures.examples.test.junit}
\end{figure}

\subsection{Generaci\'on autom\'atica de escenarios}

La automatizaci\'on de tests, aunque muy \'util, sigue requiriendo que alguien provea los tests con los cuales evaluar un programa particular. La generaci\'on de escenarios de prueba de manera autom\'atica, reducir\'ia los recursos necesarios para evaluar un programa. Siguiendo el ejemplo anterior, una gram\'atica simple servir\'ia para definir las entradas v\'alidas para luego generar expresiones aleatorias utilizando la misma. Actualmente existen numerosas aplicaciones cuyo objetivo es exclusivamente la generaci\'on autom\'atica de entradas.

Algunos de los enfoques utilizados para generaci\'on autom\'atica de entradas incluyen:

Generaci\'on \emph{aleatoria} de entradas, en donde para alg\'un conjunto de valores predefinidos se eligen de manera aleatoria elementos del mismo para usar como entrada. Esta metodolog\'ia es muy sencilla de implementar para valores de tipos no estructurados como por ejemplo, enteros y cadenas de caract\'eres. Para generaci\'on de valores de tipos estructurados, como por ejemplo una lista simplemente encadenada, es necesario combinar la generaci\'on aleatoria para cada componente que conforma el tipo estructurado. Sin embargo, \'estos tipos estructurados tienen invariantes que deben cumplidos para que una instancia (un valor de este tipo) sea considerada v\'alida. En las figuras \ref{figures.examples.testing.random.primitive} y \ref{figures.examples.testing.random.structure} se pueden ver ejemplos de generaci\'on aleatoria para tipos primitivos y estructurados respectivamente. %Un detalle a tener en cuenta en el ejemplo de generaci\'on aleatoria para tipos estructurados, es que la construcci\'on se hace mediante m\'etodos provistos por la misma estructura, en particular, el m\'etodo \lstinline|List#add(int)|. Una alternativa com\'unmente utilizada es generar de menor a mayor complejidad los componentes de las estructuras

\begin{figure}
	\begin{lstlisting}[frame=single, mathescape=true,framexleftmargin=1.5em]
    Set intInputs = new Set();
    for (int i = 0; i<10; i++) {
      int rndValue = 10 + random.nextInt(11);
      intInputs.add(rndValue);
    }
	\end{lstlisting}
	\caption{Ejemplo de generaci\'on aleatoria de 10 valores enteros entre 10 y 20}
	\label{figures.examples.testing.random.primitive}
\end{figure}

\begin{figure}
	\begin{lstlisting}[frame=single, mathescape=true,framexleftmargin=1.5em]
  Set structuredInputs = new Set();
  for (int i = 0; i<10; i++) {
    int rndSize = random.nextInt(10);
    List rndList = new List();
    for (int elemIdx = 0; elemIdx < rndSize; elemIdx++) {
      int rndValue = random.nextInt(50);
      rndList.add(rndValue);
    }
    structuredInputs.add(rndList);
  }
	\end{lstlisting}
	\caption{Ejemplo de generaci\'on aleatoria de 10 listas de enteros con tama\~no entre 0 a 10, y con valores entre 0 a 50}
	\label{figures.examples.testing.random.structure}
\end{figure}

Generaci\'on \emph{exhaustiva} de entradas consiste en utilizar todos los valores disponibles dentro de un espacio acotado. Para valores primitivos esto consistir\'ia en utilizar todos los valores entre un valor m\'inimo y un m\'aximo, evidentemente los tipos para los cuales se puede aplicar esta t\'ecnica, deben ser numerables. Para valores que corresponden a tipos estructurados, la metodolog\'ia es similar a generaci\'on aleatoria. Esta metodolog\'ia parecer\'ia en primera instancia generar una mayor confianza ya que permite eval\'uar un programa bajo todas las posibles entradas dentro de una determinada cota. La cantidad de entradas que se obtienen por generaci\'on exhaustiva llegan muy r\'apido a cantidades intratables, en \cite{bibliography.testing.generation.KoratBoyapatiKM02} que presenta una herramienta de generaci\'on exhaustiva de valores para tipos estructurados, demuestra como la cantidad de valores generados aumenta con respecto a las cotas utilizadas.

%Ejemplos de herramientas para generaci\'on autom\'atica de escenarios incluyen: \emph{Korat} \cite{bibliography.inputGeneration.korat.BoyapatiKM02} que permite generar entradas estructuralmente complejas dado un conjunto de cotas para los atributos de la estructura y una especificaci\'on mediante un predicado imperativo que indica las estructuras v\'alidas. [AGREGAR]

\subsection{El problema del or\'aculo}

A\'un teniendo la capacidad de generar escenarios de manera autom\'atica, y dado que la ejecuci\'on del programa a evaluar, bajo una entrada particular, es trivial de automatizar, el valor esperado no es generado por las herramientas de generaci\'on autom\'atica de entradas. Por ejemplo, en el caso del test en la Figura-\ref{figures.examples.test.junit}, el valor esperado \emph{16}, fue propuesto por el desarrollador del test, de manera manual. Para poder automatizar completamente la generaci\'on de tests, es entonces necesario resolver el problema de, dado una entrada y un programa a evaluar, generar el comportamiento esperado para poder validar si el programa es correcto (con respecto a esa entrada). Existen distintas soluciones a este problema:
\begin{enumerate}
	\item Manualmente, evidentemente la soluci\'on m\'as intuitiva es tener un individuo que lo haga. Esta opci\'on es un proceso muy tedioso y consume mucho tiempo, lo que puede llevar a cometer errores.
	
	\item Test diferencial, dado un programa bajo evaluaci\'on \texttt{P} y una entrada \texttt{E} sobre la cual se quiere evaluar el comportamiento de \texttt{P}, se puede generar el or\'aculo \texttt{P$\prime$(E) == P(E)} donde \texttt{P$\prime$} es un programa cuyo comportamento es equivalente al del programa a evaluar, y existe una confianza suficiente en la correctitud del mismo.
	
	\item Test de regresi\'on, un caso particular de \emph{test diferencial} es cuando una versi\'on anterior del programa a evaluar es utilizado como alternativa confiable. Esta t\'ecnica es utilizada principalmente para evaluar que el comportamiento previo de un programa no fue modificado involuntariamente al, por ejemplo, agregar nuevas caracter\'isticas.
	
	\item Especificaciones ejecutables, es posible dar una especificaci\'on de las propiedades que debe cumplir un programa. Por ejemplo, un m\'etodo que ordena listas de enteros siempre debe cumplir que los elementos en el resultado sean los mismos que en la entrada, y que est\'en ordenados. Es importante que la especificaci\'on sea ejecutable, este es un requerimiento necesario para poder utilizar a la misma como or\'aculo.
\end{enumerate}

\subsection{Modelo RIP}

La detecci\'on de una falla sigue el siguiente modelo: \emph{\texttt{R}eachability}, el defecto en el c\'odigo debe ser alcanzable por la ejecuci\'on del programa bajo alg\'un escenario particular; \emph{\texttt{I}nfection}, el defecto debe infectar el estado del programa, esto significa que al ejecutar el c\'odigo que contiene el detecto debe ocurrir un cambio en el estado tal que \'este, difiere con respecto del estado en el programa sin el defecto, o con respecto al estado esperado; \emph{\texttt{P}ropagation}, el cambio del estado debe propagarse hasta alg\'un punto observable, para permitir diferenciar una salida incorrecta (error) de la correcta.

\begin{figure}
	\begin{lstlisting}[frame=single,numbers=left, mathescape=true,framexleftmargin=1.5em]
    public int max(int a, int b) {
      int result = a;
      if (a > b) {
        result = a;
      } else if (b < a) {
        result = b;
      }
      return result;
    }
	\end{lstlisting}
	\caption{Una implementaci\'on incorrecta de un m\'etodo \emph{max}}
	\label{figures.examples.testing.rip}
\end{figure}

En la Figura-\ref{figures.examples.testing.rip} se puede ver una implementaci\'on de un programa que calcula el m\'aximo entre dos n\'umeros. El defecto se encuentra en la segunda condici\'on, \texttt{b < a}, cualquier entrada en donde no se cumpla que \texttt{a > b}, va alcanzar la sentencia con el defecto; la infecci\'on se da cuando una entrada que cumpla con, \texttt{b > a}, no cambie el valor de \texttt{result} para contener el valor de \texttt{b}; la propagaci\'on se da por que el valor incorrecto en \texttt{result}, se retorna en la \'ultima sentencia del programa. Incluso al tener un escenario que cumpla con el modelo \emph{RIP} para un defecto, \'este no va a ser detectado si no se cuenta con un or\'aculo apropiado, en este caso, validar que por ejemplo para los valores \emph{5} y \emph{3}, el resultado esperado es \emph{5}.

\subsection{Criterios de cobertura}
\label{sec:preliminares.testing.covcriteria}

%Queda en evidencia la necesidad de un criterio para evaluar la calidad de un conjunto de tests. Como condici\'on de terminaci\'on para un proceso (ya sea manual o autom\'atico) de generaci\'on de tests, as\'i como para evaluar el conjunto de tests utilizados para poder medir la relaci\'on entre el hecho de que \'estos pasen y la confianza en que el programa bajo evaluaci\'on sea correcto.

Los criterios de cobertura generan metas, o requisitos, para el test suite bajo evaluaci\'on, y eval\'uan cuantas de \'estas son satisfechas por el mismo. Dado que un criterio de evaluaci\'on para un test suite no puede, directamente analizar la capacidad del mismo en detectar fallas (salvo para aquellas conocidas), el dise\~no de \'estos se basa en encontrar relaciones entre criterios que pueden ser evaluados, y el potencial de detectar fallas. El modelo \emph{RIP} representa una base de partida para el disen\~o de criterios.

Como criterios de cobertura, aquellos denominados de \emph{caja blanca}, se basan en la estructura del programa para generar metas a cubrir. Por ejemplo, cobertura de sentencias genera como metas, la ejecuci\'on de las sentencias del programa, \'este criterio se enfoca principalmente en \emph{alcanzabilidad}. Los criterios de \emph{caja negra} se enfocan en la especificaci\'on del programa para generar metas, por ejemplo, el criterio de \emph{partici\'on de clases de equivalencia}, se enfoca en dividir las entradas en conjuntos para los cuales el comportamiento del programa deber\'ia ser el mismo, en el caso de \emph{max} uno de \'estos contendr\'ia todas las entradas tal que el primer valor es mayor al segundo.
